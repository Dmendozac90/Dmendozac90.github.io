---
layout: post
title:  "Introduction to Dynamic Mode Decomposition"
date:   2021-11-03 14:30:22 -0600
categories: python DynamicModeDecompostion
language: [python]
---

**Outline**
- [Introduction](#Introduction)
- [Mathematical Overview](#Math_Overivew)
- [The DMD Algorithm](#The DMD Algorithm)
- [The Code](#The Code)

## Introduction

The rapid growth of abundant, high-resolution data sources and machine learning techniques has increased interest in data-driven approaches that are capabable of accurately describing modern dynamical systems in order to develop new insights and physical interpretations, improve optimization and design, implement active control, and generate future state predictions.  Dynamical systems encompass a wide array of topics within science and engineering such as electrical circuits, fluid turbulance, climatology, finance, ecology, neural science, epidemiology, and any system that evolves in time. In addition to big data and machine learning, Koopman operator theory has as also augmented the general comprehension of dynamical systems by representing nonlinearities in these systems in terms of an infinite-dimensional linear operator that acts on a Hilbert space of measurement functions of the system's state. The ability to obtain linear representations of these complex nonlinear dynamical systems coupled with rich data and modern machine learning techniques, has created great potential to improve our ability to predict and control these systems. 

Dynamic mode decomposition (DMD) is a powerful data-driven technique used to discover dynamical systems from high-dimensional data. In essence, the DMD is an algorithm that identifies the best-fit (least-squares sense) linear dynamical system that advances high-dimensional measurements forwards in time. This is similar to the framework of the Koopman operator which also advances the observation of a state at a given time to the next time step. 

Part of the growing attraction of DMD is attributed to its *equation-free* nature. Although some dynamical systems could be modled from an existing set of governing equations, many of the aforementioned dynamical systems have no known governing equations. Even within systems with known governing equations, it is difficult uncover patterns that allow for the characterization of how dominant behaviors evolve in time. Additionally, the spatiotemportal structures generated by DMD allow for future state prediction and control. 

In this post I will provide a brief mathematical overview of the notation and DMD architecture. This will be followed by a discussion of the DMD algorithm and its implementation on a generated dataset to demonstrate its simple numerical implementation`. Lasltly, a breif discussion will include some of the limitations of the DMD and other viable extensions of this algorithm.

## Mathematical Overview

To motivate the application of the DMD algorithm on dynamic data, consider a dynamical systems in the form:

$$
\frac{d\mathbf{x}}{dt} = \mathbf{f}(\mathbf{x}, t; \mathbf{\mu}),
$$

where $$\mathbf{x} \in \mathbb{R}^n$$ is the system state at time $$t$$, $$\mathbf{f}(\cdot)$$ are the dynamics and $$\mu$$ is the sytem parameters. For illustrative purposes, consider the Lorenz equations with parameters $$\sigma=10$$, $$\rho=28$$, and $$\beta=8/3$$.

$$
\frac{dx}{dt} = \sigma (y - x)
$$

$$
\frac{dy}{dt} = x (\rho - z) - y
$$

$$
\frac{dz}{dt} = xy - \beta z
$$

In this context, $$\mathbf{x} = \left[\begin{array}{c} x \\ y \\ z\end{array} \right]$$ and $$\mathbf{\mu} = \left[\begin{array}{c} \sigma \\ \rho \\ \beta\end{array} \right]$$


We also consider the discrete-time dynamical system

$$
\mathbf{x_{k+1}}= \mathbf{F}(\mathbf{x_k})
$$

Discrete-time systems may also be induced from continous-time dynamics if $$\mathbf{x}_k$$  is sampled from $$\frac{d\mathbf{x}}{dt} = \mathbf{f}(\mathbf{x}, t; \mathbf{\mu})$$ discretely in time, so that $$\mathbf{x}_k = \mathbf{x}(k\Delta t)$$. For an arbitrary time $$t$$, a *flow map* $$\mathbf{F}_t$$ is defined as

$$
\mathbf{F}_t(\mathbf{x}(t_0)) = \mathbf{x}(t_0) + \displaystyle \int_{t_0}^{t_0+t} \mathbf{f}(\mathbf{x}(\tau))\,d\tau
$$

The DMD procedure approximates $$\frac{d\mathbf{x}}{dt} = \mathbf{f}(\mathbf{x}, t; \mathbf{\mu}),$$ with a linear dynamical system denoted as 

$$
\frac{d\mathbf{x}}{dt} = \mathbf{Ax}
$$

It is desirable to work with such systems because they are well understood and thus solutions for these systems are readily available. Recall that many differential equation systems can be solved by an exponential function. Thus, an initial guess of an exponential function to solve $$\frac{d\mathbf{x}}{dt} = \mathbf{Ax}$$ is a great starting point. Specifically, we will use $$ \mathbf{x} = \mathbf{\phi}\exp(\omega t)$$. Where $$\phi$$ and $$\omega$$ are to be determined. Taking the derivative of this function with respect to time, we obtain the following result  $$\frac{d\mathbf{x}}{dt} = \omega \phi \exp(\omega t)$$. Substituting these results into $$\frac{d\mathbf{x}}{dt} = \mathbf{Ax}$$ yields:

$$
 \omega \phi \exp(\omega t) = \mathbf{A} \phi \exp(\omega t)
$$

We can then cancell out scalar factor $$\exp(\omega t)$$ to obtain

$$
\mathbf{A}\phi = \omega \phi
$$

which is an eigenvalue problem. We observe that $$\phi$$ and $$\omega$$ are the eigenvector(s) and eigenvalue(s) of the matrix $$\mathbf{A}$$, respectively. Rearranging these results then yields

$$
(\mathbf{A} -\omega \mathbf{I}) \phi = 0
$$

and thus if we solve the above algebraic expression, we obtain a solution for $$\mathbf{x} = \mathbf{\phi}\exp(\omega t)$$. For a $$n$$x$$n$$ matrix, we will have $$n$$ eigenvalues and eigenvectors and thus $$n$$ independent solutions (verify this). Recall that if $$\mathbf{x_1}, \mathbf{x_2},..., \mathbf{x_n}$$ are solutions to a linear system of equations, then by the superposition principle, then the linear combination $$C_1\mathbf{x_1} + C_2\mathbf{x_2}+...+C_n\mathbf{x_n}$$ is also a solution for any constnats $$C_1, C_2,..., C_n$$. We can therefore express the solution for $$\mathbf{x}$$ as follows:


$$
\mathbf{x}(t) = \sum_{k=1}^{m} \mathbf{\phi_k} \exp(\omega t)b_k 
$$

or in matrix notation:

$$
\mathbf{x}(t) = \mathbf{\Phi} \exp(\mathbf{\Omega t})\mathbf{b}
$$

We denote the arbitrary constant $$C$$ as $$b$$ as we are given an intial $$\mathbf{x}(0)$$ and thus reducing constants to a specific value that is determined by the initial state of the system. Additionally, the coefficients are in the eigenvector basis.

In the discritized case, the solution to the dynamic system is as follows:

$$
\mathbf{x}_k = \sum_{j=1}^{r} \phi_j \lambda_j^k b_j
$$

and in matrix notation

$$
\mathbf{\Phi} \mathbf{\Lambda}^k \mathbf{b}
$$

When the DMD algorithm is applied, it will produce a low-rank eigendecomposition of the matrix $$\mathbf{A}$$ that best-fits the measured trajectory $$\mathbf{x}_k$$ for $$k = 1, 2,...,m$$ in a least-squares sense ($$\begin{Vmatrix}
\mathbf{X'} - \mathbf{A}\mathbf{X}
\end{Vmatrix}_F$$)

Note that this optimization holds only for the sampling window from which $$\mathbf{A}$$ was defined; however, this approximation can be used to make future state predictions. 

To derive the best-fit solution for the matrix operator $$\mathbf{A}$$ across the measured trajectory $$\mathbf{x}_k$$ for $$k = 1, 2,...,m$$, we must first arrange the dataset into two matricies 

$$
\mathbf{X} = 
\begin{bmatrix}
| & | & &|\\
\mathbf{x}(t_1) & \mathbf{x}(t_2) & ... & \mathbf{x}(t_{m-1})\\
| & | &  &|
\end{bmatrix}
 $$

$$
\mathbf{X'} = 
\begin{bmatrix}
| & | & &|\\
\mathbf{x}(t_2) & \mathbf{x}(t_3) & ... & \mathbf{x}(t_m)\\
| & | &  &|
\end{bmatrix}
$$

by seperating the data by a difference of $$\Delta t$$, the DMD algorithm will catpure the time dynamics of the nonlinear dynamical system via a localized linear approximation. This can be expressed in data matricies as

$$
\mathbf{X'} \approx \mathbf{A}\mathbf{X}
$$

we can then solve for $$\mathbf{A}$$ by taking the psuedoinverse and thus arriving at

$$
\mathbf{A} = \mathbf{X'X^{\dagger}}
$$

where $$\dagger$$ is the Moore-Penrose pseudoinverse.This solution minimizes the error

$$
\begin{Vmatrix}
\mathbf{X'} - \mathbf{A}\mathbf{X}
\end{Vmatrix}_F
$$

where $$\begin{Vmatrix}\cdot\end{Vmatrix}_F$$ 
is the Frobenius norm and is given by

$$
\sqrt{\sum_{j=1}^{n}\sum_{k=1}^{m}x_{jk}^2}
$$

Although we have provided the solution for the matrix $$\mathbf{A}$$, in practice, solving directly for this matrix poses computational issues which make this process intractable. A state vector within the data matrix $$\mathbf{X}$$ can possess millions of elements and thus is high-dimensional. This implies that the matrix $$\mathbf{A}$$ will have $$n^2$$ entries. Representing this matrix is therefore computationally expensive and its spectral decomposition is intractable. 

Instead of solving for $$\mathbf{A}$$ directly, the data is projected onto a low-rank subspace and then solving for a low-dimensional matrix approximation of $$\mathbf{A}$$ and is denoted as $$\mathbf{\tilde{A}}$$ and will be size of at most $$m$$ x $$m$$ as determined by the leading singular vectors. We can then compute the spectral decomposition of the reduced matrix $$\mathbf{\tilde{A}}$$. The exact steps of the DMD algorithm is expanded in the next section. 


## The DMD Algorithm

Step 1:

The first step of the DMD algorithm is to compute the singular value decompostion (SVD) of the data matrix $$\mathbf{X}$$:

$$
\mathbf{X} = \mathbf{U \Sigma V}^*
$$

however, we want to use the low-rank approximation and thus truncate the SVD to the  leading $$r$$ singular values and vectors and denote it as

$$
\mathbf{X} \approx \mathbf{\tilde{U} \tilde{\Sigma} \tilde{V}}^*
$$

where $$\mathbf{\tilde{U}} \in \mathbb{C}^{n \times r}$$, $$\mathbf{\tilde{\Sigma}} \in \mathbb{C}^{r \times r}$$, $$\mathbf{\tilde{V}} \in \mathbb{C}^{m \times r}$$, and $$*$$ denotes the conjugate transpose. The colums of the matrix $$\mathbf{\tilde{U}}$$ are known as the POD modes and they satisfy $$\mathbf{\tilde{U}}^*\mathbf{\tilde{U}}=\mathbf{I}$$. The columns of $$\mathbf{\tilde{V}}$$ are also orthonormal and satisfy $$\mathbf{\tilde{V}}^*\mathbf{\tilde{V}}=\mathbf{I}$$ We will use this fact in the next step.


Step 2:

Compute $$\mathbf{\tilde{A}}$$:

Recall that $$\mathbf{A} = \mathbf{X'X^{\dagger}}$$. Substituing the truncated SVD of $$\mathbf{X}$$ in this equation yields:

$$
\mathbf{A} = \mathbf{X'(\tilde{U} \tilde{\Sigma} \tilde{V})^{\dagger}} = \mathbf{X^{'} \tilde{V} \tilde{\Sigma}^{-1} \tilde{U}^{*}}
$$

Because we do not intendt to work with the full state of the matrix $$\mathbf{A}$$, we must project it onto the POD modes of $$\mathbf{\tilde{U}}$$. This is achieved by the following operation

$$
\mathbf{\tilde{A}} = \mathbf{\tilde{U}}^{*} \mathbf{A} \mathbf{\tilde{U}}
$$

Expressing the projection in terms of the SVD yields

$$
\mathbf{\tilde{A}} = \mathbf{\tilde{U}}^{*} (\mathbf{X^{'} \tilde{V} \tilde{\Sigma}^{-1} \tilde{U}^{*}}) \mathbf{\tilde{U}} = \mathbf{\tilde{U}}^{*} \mathbf{X^{'} \tilde{V} \tilde{\Sigma}^{-1}}
$$


Step 3:

Compute the spectral decomposition of $$\mathbf{\tilde{A}}$$

$$
\mathbf{\tilde{A}W = W \Lambda}
$$
 

 Step 4:

 Reconstruct the high-dimensional DMD modes $$\Phi$$ using the eigenvectors of the refuced matrix $$\mathbf{\tilde{A}}$$ and the time-shifted matrix $$\mathbf{X}^{'}$$

 $$
\Phi = \mathbf{X}^{'} \mathbf{\tilde{V} \tilde{\Sigma}}^{-1} \mathbf{W}
 $$

 An interesting fact to point out is that although we used the low-dimensional eigenvectors $$\mathbf{W}$$ to compute the high-dimensional DMD modes, we can demonstrate that the DMD modes are eigenvecors of the high-dimensional matrix $$\mathbf{A}$$

 We begin by looking at 

$$
\mathbf{A} \Phi = (\mathbf{X'}\mathbf{V}\mathbf{\Sigma^{-1}}\mathbf{U^*}) (\mathbf{X}^{'} \mathbf{\tilde{V} \tilde{\Sigma}}^{-1} \mathbf{W})
$$

Looking at this expression, we can observe that the definition of $$\mathbf{\tilde{A}}$$ resides in the expansion and thus we can substitute $$\mathbf{\tilde{A}}$$ in for $$\mathbf{\tilde{U}}^{*} \mathbf{X^{'} \tilde{V} \tilde{\Sigma}^{-1}}$$ and rewrite as follows

$$
\mathbf{A} \Phi = \mathbf{X'}\mathbf{V}\mathbf{\Sigma^{-1}} \mathbf{\tilde{A}} \mathbf{W}
$$

We can then use the fact that $$\mathbf{\tilde{A}W = W \Lambda}$$ and thus we obtain 

$$
\mathbf{A} \Phi = \mathbf{X'}\mathbf{V}\mathbf{\Sigma^{-1}} \mathbf{W} \mathbf{\Lambda}
$$

Lastly, we can now substitute the definition of a DMD mode to obtain

$$
\mathbf{A} \mathbf{\Phi} = \mathbf{\Phi \Lambda}
$$

Thus arriving at the conclusion that the DMD modes determined by the low-dimesnional eigenvectors of $$\mathbf{\tilde{A}}$$ are in fact the eigenvectors of the high-demsional matrix $$\mathbf{A}$$

## The Code

To demonstrate the DMD algorithm, we first consider an example in which we know the structure of the underlying dynamics. In this example, we combine two mixed spatiotemporal signals and apply the DMD algorithm to decompose the signal into its constituents. 

The two signals are

$$
f(x,t) = f_1(x,t) + f_2(x,t) = \frac{1}{\cosh}(x+3)\exp(i2.3t) + \frac{2}{\cosh}(x) \tanh(x) \exp(i2.8t)
$$

We first import the nescessary libraries

{% highlight python%}
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
{% endhighlight%}

Next, we define the two functions that will be used to create the mixed signals

{% highlight python %}
#Define the functions 
def f1(xx, tt):
    y_1 = (1. / np.cosh(xx + 3)) * np.exp(2.3j * tt)
    return y_1

def f2(xx, tt):
    y_2 = (2. / np.cosh(xx)) * np.tanh(xx) * np.exp(2.8j * tt)
    return y_2
{% endhighlight %}

The space and time discretizations are defined and the data to be analyzed is generated as follows

{% highlight python %}
#Define time and space discretizations
xi = np.linspace(-10, 10, 400)
t = np.linspace(0, 4*np.pi, 200)
dt = t[1] - t[0]
xx, tt = np.meshgrid(xi, t)
X = f1(xx, tt) + f2(xx, tt)
{% endhighlight %}

The individual spatiotemporal signals $$f_1(x,t)$$ and $$f_2(x,t)$$ are displayed below. The two frequencies present in the functions are $$\omega_1$$ = 2.3 and $$\omega_2$$ = 2.8.

<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="/assets/img/DynamicModeDecomp/f1.html" height="525" width="48%"></iframe>

<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="/assets/img/DynamicModeDecomp/f2.html" height="525" width="48%"></iframe>

The individual signals are summed and the resulting data is displayed in the third column in the figure below. The y-axis corresponds to time component. 

<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="/assets/img/DynamicModeDecomp/Surface_Plot.html" height="525" width="100%"></iframe>

Now that we have the data, we are ready to apply the DMD algorithm. Frist, we create out data matrices and denote them as $$\mathbf{X}_1$$ and $$\mathbf{X}_2$$

{% highlight python %}
X_1 = X.T[:, :-1]
X_2 = X.T[:, 1:]
{% endhighlight %}

Next, we compute the SVD of the matrix $$\mathbf{X}_1$$ 

{% highlight python %}
U, Sigma, V = np.linalg.svd(X_1)
V = V.conj()
{% endhighlight %}

Plotting the first ten singular values, we can observe that the first two singular values caputre over 99% of the system's energy and thus we can truncate the SVD decomposition to rank = 2.

{% highlight python %}
fig = go.Figure()

fig.add_trace(go.Scatter(x=np.arange(X.shape[1]), y=Sigma/Sigma.sum(), mode="markers",
                marker=dict(symbol="circle-open-dot", color='black', size=10)))
fig.update_yaxes(type="log")
fig.update_xaxes(range=[-1, 10])
fig.update_layout(
        title=dict(text="Singular Values", x=0.5),
        xaxis_title = "Singular Values, σk",
        yaxis_title = "Normalized Singular Values, σk/Σσk"
    )

{% endhighlight %}

<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="/assets/img/DynamicModeDecomp/SVD.html" height="525" width="100%"></iframe>

{% highlight python %}
U, Sigma, V = U[:, :2], Sigma[:2], V[:2, :]
{% endhighlight %}

We then compute $$\mathbf{\tilde{A}}$$ and its spectral decomposition 

{% highlight python %}
A_tilde = np.linalg.multi_dot([U.T, X_2, V.T, np.diag(np.reciprocal(Sigma))])
Lambda, W = np.linalg.eig(A_tilde)
{% endhighlight %}

Lastly, the high-dimensional DMD modes are reconstructed

{% highlight python %}
Phi = np.linalg.multi_dot([X_2, V.T, np.diag(np.reciprocal(Sigma)), W])
{% endhighlight %}

Now that we have conducted the nescesarry computations, we turn to the continuous-time solution 

$$
\mathbf{x}(t) = \mathbf{\Phi} \exp(\mathbf{\Omega} t)\mathbf{b}
$$

We note that $$\mathbf{b}$$ remains to be calculated. Recall that $$\mathbf{b}$$ are the constants specified by the intial conditions in the eigenvector basis. Thus to derive the solution, we can substitute 0 in for $$t$$ in the equation above and obtain

$$
\mathbf{x}_1 = \mathbf{\phi b}
$$

and we then solve for $$\mathbf{b}$$

$$
\mathbf{b} = \mathbf{\phi}^{\dagger} \mathbf{x}_1
$$

we run the following code to obtain $$b$$

{% highlight python %}
b, residuals, rank, sigma = np.linalg.lstsq(Phi, x_1, rcond=None)
{% endhighlight %}

the matrix $$\Omega$$ is defined as a diagonal matrix with its diagonal entries defined as $$\omega = \log(\lambda_{k})/ \Delta{t}$$

{% highlight python %}
Omega = np.log(Lambda)/dt
{% endhighlight %}

If we print the values of Omega, we observe that the imaginary components of Omega display the underlying frequencies in 

$$
\frac{2}{\cosh}(x) \tanh(x) \exp(i2.8t), \frac{1}{\cosh}(x+3)\exp(i2.3t)
$$

We can also plot the modes obtained by the DMD algorithm 

{% highlight python %}
[-8.54346131e-15+2.8j -6.84026324e-15+2.3j]
{% endhighlight %}

Note that the DMD modes correctly identify the two different spatial signals generated by $$f_1(x,t), f_2(x,t)$$

<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="/assets/img/DynamicModeDecomp/DMD modes.html" height="525" width="100%"></iframe>

We can now construct the dynamics of the system by evaluating $$\exp({\mathbf{\Omega} t}) \mathbf{b}$$

{% highlight python %}
t_exp = np.arange(X.T.shape[1]) * dt
temp = np.repeat(Omega.reshape(-1,1), t_exp.size, axis=1)
dynamics = np.exp(temp * t_exp) * b.reshape(2, -1)
{% endhighlight %}

With the dynamics and the DMD modes, we can reconstruct our data as follows

{% highlight python %}
X_dmd = Phi @ dynamics
{% endhighlight %}

We can evaluate the accuracy of the reconstruced data by visualizing the difference between the two datasets

<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="/assets/img/DynamicModeDecomp/Errors.html" height="525" width="100%"></iframe>

Note that the differences are visualized on a femtometer scale. The minor differences between the true and DMD-generated data are virutally zero and thus the two datasets are virtually identical. 

We can also predict the future state of the system arbitrarily long. We plot the last state of the system generated by the function and predict 200 time steps into the futre. 

<iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="/assets/img/DynamicModeDecomp/Prediction.html" height="525" width="100%"></iframe>


